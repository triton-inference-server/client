# Copyright 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#  * Neither the name of NVIDIA CORPORATION nor the names of its
#    contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

import argparse
import logging
from pathlib import Path

from genai_pa.constants import LOGGER_NAME

logger = logging.getLogger(LOGGER_NAME)


def prune_args(args: argparse.ArgumentParser) -> argparse.ArgumentParser:
    """
    Prune the parsed arguments to remove args with None or False values.
    """
    return argparse.Namespace(
        **{k: v for k, v in vars(args).items() if v is not None if v is not False}
    )


### Handlers ###


# NOTE: Placeholder
def handler(args):
    from genai_pa.wrapper import Profiler

    Profiler.run(model=args.model, args=args)


### Parsers ###


def add_model_args(parser):
    parser.add_argument(
        "-m",
        "--model",
        type=str,
        required=True,
        help=f"The name of the model to benchmark.",
    )


def add_profile_args(parser, exclusive_group):
    parser.add_argument(
        "-b",
        type=int,
        default=1,
        required=False,
        help="The batch size to benchmark. The default value is 1.",
    )
    exclusive_group.add_argument(
        "--concurrency",
        type=int,
        required=False,
        help="Sets the concurrency value to benchmark.",
    )
    parser.add_argument(
        "--max-threads",
        type=int,
        default=16,
        required=False,
        help="Sets the maximum number of threads that will be "
        "created for providing desired concurrency or request rate. "
        "However, when running in synchronous mode,this value will be ignored. "
        "The default value is 16.",
    )
    # TODO: necessary?
    # parser.add_argument(
    #     "--output-length",
    #     type=int,
    #     default=128,
    #     required=False,
    #     help="The output length (tokens) to use for benchmarking LLMs. (Default: 128)",
    # )
    parser.add_argument(
        "--profile-export-file",
        type=Path,
        default="profile_export.json",
        help="Specifies the path where the profile export will be "
        "generated. By default, the profile export will not be "
        "generated.",
    )
    exclusive_group.add_argument(
        "--request-rate",
        type=float,
        required=False,
        help="Sets the request rate for the load generated by PA. ",
    )
    parser.add_argument(
        "--service-kind",
        type=str,
        choices=["triton", "openai"],
        default="triton",
        required=False,
        help="Describes the kind of service perf_analyzer will "
        'generate load for. The options are "triton" and '
        '"openai". The default value is "triton".',
    )
    parser.add_argument(
        "--streaming",
        action="store_true",
        required=False,
        help=f"Enables the use of the streaming API.",
    )
    parser.add_argument(
        "--version",
        action="store_true",
        required=False,
        help=f"Prints the version and exits. By default, it is set false.",
    )


def add_endpoint_args(parser):
    parser.add_argument(
        "-u",
        "--url",
        type=str,
        default="localhost:8001",
        required=False,
        help="URL of the endpoint to target for benchmarking.",
    )


def add_dataset_args(parser):
    pass
    # TODO: Do we want to remove dataset and tokenizer?
    # parser.add_argument(
    #     "--dataset",
    #     type=str,
    #     default="OpenOrca",
    #     choices=["OpenOrca", "cnn_dailymail"],
    #     required=False,
    #     help="HuggingFace dataset to use for the benchmark.",
    # )
    # parser.add_argument(
    #     "--tokenizer",
    #     type=str,
    #     default="auto",
    #     choices=["auto"],
    #     required=False,
    #     help="The HuggingFace tokenizer to use to interpret token metrics from final text results",
    # )


### Entrypoint ###


# Optional argv used for testing - will default to sys.argv if None.
def parse_args(argv=None):
    parser = argparse.ArgumentParser(
        prog="genai-pa",
        description="CLI to profile LLMs and Generative AI models with Perf Analyzer",
    )
    parser.set_defaults(func=handler)

    # Conceptually group args for easier visualization
    model_group = parser.add_argument_group("Model")
    add_model_args(model_group)

    profile_group = parser.add_argument_group("Profiling")
    load_management_group = profile_group.add_mutually_exclusive_group()
    add_profile_args(profile_group, load_management_group)

    endpoint_group = parser.add_argument_group("Endpoint")
    add_endpoint_args(endpoint_group)

    dataset_group = parser.add_argument_group("Dataset")
    add_dataset_args(dataset_group)

    args = parser.parse_args(argv)

    # Update GenAI-PA non-range attributes to range format for PA
    for attr_key in ["concurrency", "request_rate"]:
        attr_val = getattr(args, attr_key)
        if attr_val is not None:
            setattr(args, f"{attr_key}_range", f"{attr_val}:{attr_val}")
        delattr(args, attr_key)

    args = prune_args(args)
    return args
