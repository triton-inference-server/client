# Copyright 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#  * Neither the name of NVIDIA CORPORATION nor the names of its
#    contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

import argparse
import logging
from pathlib import Path

from genai_pa.constants import (
    CNN_DAILY_MAIL,
    DEFAULT_GRPC_URL,
    DEFAULT_HTTP_URL,
    LOGGER_NAME,
    OPEN_ORCA,
)

logger = logging.getLogger(LOGGER_NAME)


def _prune_args(args: argparse.ArgumentParser) -> argparse.ArgumentParser:
    """
    Prune the parsed arguments to remove args with None or False values.
    """
    return argparse.Namespace(
        **{k: v for k, v in vars(args).items() if v is not None if v is not False}
    )


def _update_load_manager_args(args: argparse.ArgumentParser) -> argparse.ArgumentParser:
    """
    Update GenAI-PA load manager attributes to PA format
    """
    for attr_key in ["concurrency", "request_rate"]:
        attr_val = getattr(args, attr_key)
        if attr_val is not None:
            setattr(args, f"{attr_key}_range", f"{attr_val}")
        delattr(args, attr_key)
    return args


def _verify_valid_arg_combination(
    args: argparse.ArgumentParser,
) -> argparse.ArgumentParser:
    # Verify protocol and default url match
    if getattr(args, "i") == "grpc" and getattr(args, "u") == DEFAULT_HTTP_URL:
        setattr(args, "u", DEFAULT_GRPC_URL)

    return args


### Handlers ###


def handler(args, extra_args):
    from genai_pa.wrapper import Profiler

    Profiler.run(model=args.model, args=args, extra_args=extra_args)


### Parsers ###


def _add_model_args(parser):
    model_group = parser.add_argument_group("Model")

    model_group.add_argument(
        "-m",
        "--model",
        type=str,
        required=True,
        help=f"The name of the model to benchmark.",
    )


def _add_profile_args(parser):
    profile_group = parser.add_argument_group("Profiling")
    load_management_group = profile_group.add_mutually_exclusive_group(required=True)

    profile_group.add_argument(
        "-b",
        "--batch-size",
        type=int,
        default=1,
        required=False,
        help="The batch size to benchmark. The default value is 1.",
    )
    load_management_group.add_argument(
        "--concurrency",
        type=int,
        required=False,
        help="Sets the concurrency value to benchmark.",
    )
    profile_group.add_argument(
        "--max-threads",
        type=int,
        default=16,
        required=False,
        help="Sets the maximum number of threads that will be "
        "created for providing desired concurrency or request rate. "
        "The default value is 16.",
    )
    # TODO: necessary?
    # parser.add_argument(
    #     "--output-length",
    #     type=int,
    #     default=128,
    #     required=False,
    #     help="The output length (tokens) to use for benchmarking LLMs. (Default: 128)",
    # )
    profile_group.add_argument(
        "--profile-export-file",
        type=Path,
        default="profile_export.json",
        help="Specifies the path where the profile export will be "
        "generated. By default, the profile export will not be "
        "generated.",
    )
    load_management_group.add_argument(
        "--request-rate",
        type=float,
        required=False,
        help="Sets the request rate for the load generated by PA. ",
    )
    profile_group.add_argument(
        "--service-kind",
        type=str,
        choices=["triton", "openai"],
        default="triton",
        required=False,
        help="Describes the kind of service perf_analyzer will "
        'generate load for. The options are "triton" and '
        '"openai". The default value is "triton".',
    )
    profile_group.add_argument(
        "--streaming",
        action="store_true",
        required=False,
        help=f"Enables the use of the streaming API.",
    )
    profile_group.add_argument(
        "--version",
        action="store_true",
        required=False,
        help=f"Prints the version and exits.",
    )


def _add_endpoint_args(parser):
    endpoint_group = parser.add_argument_group("Endpoint")

    endpoint_group.add_argument(
        "-i",
        type=str.lower,
        choices=["http", "grpc"],
        default="http",
        required=False,
        help=f"Sets the protocol used to communicate with inference service",
    )

    endpoint_group.add_argument(
        "-u",
        "--url",
        type=str,
        default=DEFAULT_HTTP_URL,
        required=False,
        dest="u",
        metavar="URL",
        help="URL of the endpoint to target for benchmarking.",
    )


def _add_dataset_args(parser):
    dataset_group = parser.add_argument_group("Dataset")

    dataset_group.add_argument(
        "--dataset",
        type=str.lower,
        default=OPEN_ORCA,
        choices=[OPEN_ORCA, CNN_DAILY_MAIL],
        required=False,
        help="HuggingFace dataset to use for benchmarking.",
    )

    # dataset_group.add_argument(
    #     "--tokenizer",
    #     type=str,
    #     default="auto",
    #     choices=["auto"],
    #     required=False,
    #     help="The HuggingFace tokenizer to use to interpret token metrics from final text results",
    # )


### Entrypoint ###


# Optional argv used for testing - will default to sys.argv if None.
def parse_args(argv=None):
    parser = argparse.ArgumentParser(
        prog="genai-pa",
        description="CLI to profile LLMs and Generative AI models with Perf Analyzer",
    )
    parser.set_defaults(func=handler)

    # Conceptually group args for easier visualization
    _add_model_args(parser)
    _add_profile_args(parser)
    _add_endpoint_args(parser)
    _add_dataset_args(parser)

    args, extra_args = parser.parse_known_args(argv)
    # strip off the "--" demarking the pass through arguments
    extra_args = extra_args[1:]

    args = _update_load_manager_args(args)
    args = _verify_valid_arg_combination(args)
    args = _prune_args(args)

    return args, extra_args
